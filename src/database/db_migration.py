# æ•°æ®åº“è¿ç§»å·¥å…·
import sqlite3
import os
import json
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.utils.security import hash_password

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    handlers=[
                        logging.FileHandler("db_migration.log"),
                        logging.StreamHandler()
                    ])
logger = logging.getLogger("DBMigration")




class DBMigration:
    """æ•°æ®åº“è¿ç§»ç®¡ç†ç±»"""
    
    def __init__(self, db_path):
        """
        åˆå§‹åŒ–è¿ç§»ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = db_path
        self.migrations_dir = os.path.join(os.path.dirname(db_path), "migrations")
        self.migration_history = os.path.join(self.migrations_dir, "history.json")
        
        # ç¡®ä¿è¿ç§»ç›®å½•å­˜åœ¨
        if not os.path.exists(self.migrations_dir):
            os.makedirs(self.migrations_dir)
            logger.info(f"åˆ›å»ºè¿ç§»ç›®å½•: {self.migrations_dir}")
        
        # ç¡®ä¿è¿ç§»å†å²æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(self.migration_history):
            with open(self.migration_history, 'w', encoding='utf-8') as f:
                json.dump([], f, ensure_ascii=False, indent=2)
                logger.info(f"åˆ›å»ºè¿ç§»å†å²æ–‡ä»¶: {self.migration_history}")
    
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        return sqlite3.connect(self.db_path)
    
    def get_migration_history(self):
        """è·å–å·²æ‰§è¡Œçš„è¿ç§»è®°å½•"""
        try:
            with open(self.migration_history, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¯»å–è¿ç§»å†å²å¤±è´¥: {str(e)}")
            return []
    
    def save_migration_history(self, history):
        """ä¿å­˜è¿ç§»å†å²"""
        try:
            with open(self.migration_history, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
                logger.info(f"ä¿å­˜è¿ç§»å†å²æˆåŠŸ")
        except Exception as e:
            logger.error(f"ä¿å­˜è¿ç§»å†å²å¤±è´¥: {str(e)}")
    
    def initialize_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“ï¼Œåˆ›å»ºå¿…è¦çš„è¡¨ç»“æ„"""
        logger.info("å¼€å§‹åˆå§‹åŒ–æ•°æ®åº“...")
        
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # 1. åˆ›å»ºç”¨æˆ·è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT NOT NULL UNIQUE,
                password TEXT NOT NULL,
                fullname TEXT NOT NULL,
                email TEXT,
                role TEXT DEFAULT 'user',
                status TEXT DEFAULT 'active',
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                last_login TEXT
            )
            """)
            logger.info("åˆ›å»ºusersè¡¨æˆåŠŸ")
            
            # 2. åˆ›å»ºè´¦æˆ·è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS accounts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                account_type TEXT NOT NULL,
                currency TEXT DEFAULT 'CNY',
                balance REAL DEFAULT 0.0,
                description TEXT,
                status TEXT DEFAULT 'active',
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
            """)
            logger.info("åˆ›å»ºaccountsè¡¨æˆåŠŸ")
            
            # 3. åˆ›å»ºåˆ†ç±»è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS categories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                category_type TEXT NOT NULL,
                parent_id INTEGER,
                icon TEXT DEFAULT 'default',
                color TEXT DEFAULT '#007bff',
                description TEXT,
                is_system INTEGER DEFAULT 0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (parent_id) REFERENCES categories(id)
            )
            """)
            logger.info("åˆ›å»ºcategoriesè¡¨æˆåŠŸ")
            
            # 4. åˆ›å»ºäº¤æ˜“è®°å½•è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS transactions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                transaction_type TEXT NOT NULL,
                amount REAL NOT NULL,
                account_id INTEGER NOT NULL,
                category_id INTEGER NOT NULL,
                transaction_date TEXT NOT NULL,
                description TEXT,
                receipt_number TEXT,
                payment_method TEXT,
                created_by INTEGER,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (account_id) REFERENCES accounts(id),
                FOREIGN KEY (category_id) REFERENCES categories(id),
                FOREIGN KEY (created_by) REFERENCES users(id)
            )
            """)
            logger.info("åˆ›å»ºtransactionsè¡¨æˆåŠŸ")
            
            # 5. åˆ›å»ºé¢„ç®—è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS budgets (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category_id INTEGER NOT NULL,
                amount REAL NOT NULL,
                period TEXT NOT NULL,
                start_date TEXT NOT NULL,
                end_date TEXT NOT NULL,
                description TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (category_id) REFERENCES categories(id)
            )
            """)
            logger.info("åˆ›å»ºbudgetsè¡¨æˆåŠŸ")
            
            # 6. åˆ›å»ºé™„ä»¶è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS attachments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                transaction_id INTEGER NOT NULL,
                file_path TEXT NOT NULL,
                file_name TEXT NOT NULL,
                file_size INTEGER,
                file_type TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (transaction_id) REFERENCES transactions(id)
            )
            """)
            logger.info("åˆ›å»ºattachmentsè¡¨æˆåŠŸ")
            
            # 7. åˆ›å»ºç³»ç»Ÿé…ç½®è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS system_configs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                config_key TEXT NOT NULL UNIQUE,
                config_value TEXT,
                config_type TEXT DEFAULT 'string',
                description TEXT,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
            """)
            logger.info("åˆ›å»ºsystem_configsè¡¨æˆåŠŸ")
            
            # 8. åˆ›å»ºæ“ä½œæ—¥å¿—è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS operation_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                operation_type TEXT NOT NULL,
                operation_desc TEXT,
                operation_table TEXT,
                operation_data TEXT,
                ip_address TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(id)
            )
            """)
            logger.info("åˆ›å»ºoperation_logsè¡¨æˆåŠŸ")
            
            # 9. åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_transactions_date ON transactions(transaction_date)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_transactions_account ON transactions(account_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_transactions_category ON transactions(category_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_transactions_type ON transactions(transaction_type)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_users_username ON users(username)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_accounts_status ON accounts(status)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_categories_type ON categories(category_type)")
            logger.info("åˆ›å»ºç´¢å¼•æˆåŠŸ")
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            if 'conn' in locals():
                conn.rollback()
            raise
        finally:
            if 'conn' in locals():
                conn.close()
    
    def insert_initial_data(self):
        """æ’å…¥åˆå§‹æ•°æ®"""
        logger.info("å¼€å§‹æ’å…¥åˆå§‹æ•°æ®...")
        
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # 1. æ£€æŸ¥æ˜¯å¦å·²æœ‰ç®¡ç†å‘˜ç”¨æˆ·
            cursor.execute("SELECT COUNT(*) FROM users WHERE role = 'admin'")
            if cursor.fetchone()[0] == 0:
                # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·ï¼Œä½¿ç”¨å“ˆå¸Œå¤„ç†çš„å¯†ç 
                admin_password = 'admin123'
                hashed_password = hash_password(admin_password)
                cursor.execute(
                    "INSERT INTO users (username, password, fullname, email, role) VALUES (?, ?, ?, ?, ?)",
                    ('admin', hashed_password, 'ç³»ç»Ÿç®¡ç†å‘˜', 'admin@example.com', 'admin')
                )
                logger.info("åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·æˆåŠŸ")
            
            # 2. æ£€æŸ¥æ˜¯å¦å·²æœ‰é»˜è®¤è´¦æˆ·
            cursor.execute("SELECT COUNT(*) FROM accounts")
            if cursor.fetchone()[0] == 0:
                # åˆ›å»ºé»˜è®¤è´¦æˆ·
                default_accounts = [
                    ('ç°é‡‘è´¦æˆ·', 'asset', 'CNY', 0.0, 'ä¸»è¦ç”¨äºè®°å½•ç°é‡‘æ”¶æ”¯', 'active'),
                    ('é“¶è¡Œå­˜æ¬¾', 'asset', 'CNY', 0.0, 'ä¸»è¦ç”¨äºè®°å½•é“¶è¡Œè´¦æˆ·æ”¶æ”¯', 'active'),
                    ('åº”æ”¶è´¦æ¬¾', 'asset', 'CNY', 0.0, 'è®°å½•å®¢æˆ·æ¬ æ¬¾', 'active'),
                    ('åº”ä»˜è´¦æ¬¾', 'liability', 'CNY', 0.0, 'è®°å½•æ¬ ä¾›åº”å•†æ¬¾é¡¹', 'active'),
                    ('è‚¡æœ¬', 'equity', 'CNY', 0.0, 'è®°å½•å…¬å¸æ³¨å†Œèµ„æœ¬', 'active')
                ]
                
                for account in default_accounts:
                    cursor.execute(
                        "INSERT INTO accounts (name, account_type, currency, balance, description, status) VALUES (?, ?, ?, ?, ?, ?)",
                        account
                    )
                logger.info("åˆ›å»ºé»˜è®¤è´¦æˆ·æˆåŠŸ")
            
            # 3. æ£€æŸ¥æ˜¯å¦å·²æœ‰é»˜è®¤åˆ†ç±»
            cursor.execute("SELECT COUNT(*) FROM categories")
            if cursor.fetchone()[0] == 0:
                # åˆ›å»ºé»˜è®¤æ”¶å…¥åˆ†ç±»
                income_categories = [
                    ('ä¸»è¥ä¸šåŠ¡æ”¶å…¥', 'income', None, 'ğŸ’°', '#28a745', 'default', 'é”€å”®å•†å“æˆ–æä¾›æœåŠ¡çš„æ”¶å…¥', 1),
                    ('å…¶ä»–ä¸šåŠ¡æ”¶å…¥', 'income', None, 'ğŸ’µ', '#20c997', 'default', 'éä¸»è¥ä¸šåŠ¡çš„æ”¶å…¥', 1),
                    ('æŠ•èµ„æ”¶ç›Š', 'income', None, 'ğŸ“ˆ', '#6f42c1', 'default', 'æŠ•èµ„è·å¾—çš„æ”¶ç›Š', 1),
                    ('è¥ä¸šå¤–æ”¶å…¥', 'income', None, 'ğŸ', '#ffc107', 'default', 'ä¸ç”Ÿäº§ç»è¥æ— ç›´æ¥å…³ç³»çš„æ”¶å…¥', 1)
                ]
                
                for category in income_categories:
                    cursor.execute(
                        "INSERT INTO categories (name, category_type, parent_id, icon, color, description, is_system) VALUES (?, ?, ?, ?, ?, ?, ?)",
                        category[:-1]  # å»æ‰æœ€åä¸€ä¸ªå…ƒç´ ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦'default'å­—æ®µ
                    )
                
                # åˆ›å»ºé»˜è®¤æ”¯å‡ºåˆ†ç±»
                expense_categories = [
                    ('ä¸»è¥ä¸šåŠ¡æˆæœ¬', 'expense', None, 'ğŸ“¦', '#dc3545', 'default', 'é”€å”®å•†å“æˆ–æä¾›æœåŠ¡çš„æˆæœ¬', 1),
                    ('é”€å”®è´¹ç”¨', 'expense', None, 'ğŸ¢', '#fd7e14', 'default', 'é”€å”®è¿‡ç¨‹ä¸­å‘ç”Ÿçš„å„é¡¹è´¹ç”¨', 1),
                    ('ç®¡ç†è´¹ç”¨', 'expense', None, 'âš™ï¸', '#17a2b8', 'default', 'ä¼ä¸šç®¡ç†éƒ¨é—¨å‘ç”Ÿçš„è´¹ç”¨', 1),
                    ('è´¢åŠ¡è´¹ç”¨', 'expense', None, 'ğŸ’¸', '#6c757d', 'default', 'ç­¹é›†ç”Ÿäº§ç»è¥æ‰€éœ€èµ„é‡‘ç­‰å‘ç”Ÿçš„è´¹ç”¨', 1),
                    ('è¥ä¸šå¤–æ”¯å‡º', 'expense', None, 'âŒ', '#343a40', 'default', 'ä¸ç”Ÿäº§ç»è¥æ— ç›´æ¥å…³ç³»çš„æ”¯å‡º', 1)
                ]
                
                for category in expense_categories:
                    cursor.execute(
                        "INSERT INTO categories (name, category_type, parent_id, icon, color, description, is_system) VALUES (?, ?, ?, ?, ?, ?, ?)",
                        category[:-1]  # å»æ‰æœ€åä¸€ä¸ªå…ƒç´ ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦'default'å­—æ®µ
                    )
                
                logger.info("åˆ›å»ºé»˜è®¤åˆ†ç±»æˆåŠŸ")
            
            # 4. æ£€æŸ¥æ˜¯å¦å·²æœ‰ç³»ç»Ÿé…ç½®
            cursor.execute("SELECT COUNT(*) FROM system_configs")
            if cursor.fetchone()[0] == 0:
                # æ’å…¥é»˜è®¤ç³»ç»Ÿé…ç½®
                default_configs = [
                    ('company_name', 'æœªè®¾ç½®å…¬å¸åç§°', 'string', 'å…¬å¸åç§°'),
                    ('currency', 'CNY', 'string', 'é»˜è®¤è´§å¸'),
                    ('decimal_places', '2', 'integer', 'å°æ•°ä½æ•°'),
                    ('auto_backup', 'true', 'boolean', 'è‡ªåŠ¨å¤‡ä»½'),
                    ('backup_frequency', 'daily', 'string', 'å¤‡ä»½é¢‘ç‡'),
                    ('language', 'zh_CN', 'string', 'ç³»ç»Ÿè¯­è¨€'),
                    ('theme', 'light', 'string', 'ç³»ç»Ÿä¸»é¢˜'),
                    ('default_period', 'month', 'string', 'é»˜è®¤æŠ¥è¡¨å‘¨æœŸ'),
                    ('data_retention_days', '365', 'integer', 'æ•°æ®ä¿ç•™å¤©æ•°'),
                    ('log_level', 'INFO', 'string', 'æ—¥å¿—çº§åˆ«')
                ]
                
                for config in default_configs:
                    cursor.execute(
                        "INSERT INTO system_configs (config_key, config_value, config_type, description) VALUES (?, ?, ?, ?)",
                        config
                    )
                
                logger.info("åˆ›å»ºé»˜è®¤ç³»ç»Ÿé…ç½®æˆåŠŸ")
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            logger.info("åˆå§‹æ•°æ®æ’å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ’å…¥åˆå§‹æ•°æ®å¤±è´¥: {str(e)}")
            if 'conn' in locals():
                conn.rollback()
            raise
        finally:
            if 'conn' in locals():
                conn.close()
    
    def create_migration(self, migration_name):
        """
        åˆ›å»ºæ–°çš„è¿ç§»æ–‡ä»¶
        
        Args:
            migration_name: è¿ç§»åç§°
            
        Returns:
            str: è¿ç§»æ–‡ä»¶è·¯å¾„
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            migration_file = f"{timestamp}_{migration_name}.sql"
            migration_path = os.path.join(self.migrations_dir, migration_file)
            
            # åˆ›å»ºç©ºçš„è¿ç§»æ–‡ä»¶
            with open(migration_path, 'w', encoding='utf-8') as f:
                f.write(f"-- è¿ç§»æ–‡ä»¶: {migration_name}\n")
                f.write(f"-- åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("-- åœ¨æ­¤å¤„ç¼–å†™SQLè¯­å¥\n")
            
            logger.info(f"åˆ›å»ºè¿ç§»æ–‡ä»¶æˆåŠŸ: {migration_file}")
            return migration_path
            
        except Exception as e:
            logger.error(f"åˆ›å»ºè¿ç§»æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise
    
    def execute_migration(self, migration_file):
        """
        æ‰§è¡ŒæŒ‡å®šçš„è¿ç§»æ–‡ä»¶
        
        Args:
            migration_file: è¿ç§»æ–‡ä»¶åç§°
        """
        try:
            # æ£€æŸ¥è¿ç§»æ˜¯å¦å·²æ‰§è¡Œ
            history = self.get_migration_history()
            if migration_file in [m['file'] for m in history]:
                logger.warning(f"è¿ç§»æ–‡ä»¶å·²æ‰§è¡Œ: {migration_file}")
                return False
            
            # è¯»å–è¿ç§»æ–‡ä»¶
            migration_path = os.path.join(self.migrations_dir, migration_file)
            if not os.path.exists(migration_path):
                logger.error(f"è¿ç§»æ–‡ä»¶ä¸å­˜åœ¨: {migration_file}")
                return False
            
            with open(migration_path, 'r', encoding='utf-8') as f:
                sql_statements = f.read()
            
            # æ‰§è¡ŒSQLè¯­å¥
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # åˆ†å‰²å¹¶æ‰§è¡Œå¤šä¸ªSQLè¯­å¥
            for statement in sql_statements.split(';'):
                statement = statement.strip()
                if statement and not statement.startswith('--'):
                    cursor.execute(statement)
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            
            # æ›´æ–°è¿ç§»å†å²
            migration_record = {
                'file': migration_file,
                'executed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            history.append(migration_record)
            self.save_migration_history(history)
            
            logger.info(f"è¿ç§»æ–‡ä»¶æ‰§è¡ŒæˆåŠŸ: {migration_file}")
            return True
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œè¿ç§»æ–‡ä»¶å¤±è´¥: {str(e)}")
            if 'conn' in locals():
                conn.rollback()
            raise
        finally:
            if 'conn' in locals():
                conn.close()
    
    def migrate_all(self):
        """æ‰§è¡Œæ‰€æœ‰æœªæ‰§è¡Œçš„è¿ç§»æ–‡ä»¶"""
        logger.info("å¼€å§‹æ‰§è¡Œæ‰€æœ‰æœªæ‰§è¡Œçš„è¿ç§»æ–‡ä»¶...")
        
        try:
            # è·å–å·²æ‰§è¡Œçš„è¿ç§»
            history = self.get_migration_history()
            executed_migrations = [m['file'] for m in history]
            
            # è·å–æ‰€æœ‰è¿ç§»æ–‡ä»¶
            migration_files = [f for f in os.listdir(self.migrations_dir) 
                             if f.endswith('.sql') and f != 'init.sql']
            
            # æŒ‰æ—¶é—´é¡ºåºæ’åº
            migration_files.sort()
            
            # æ‰§è¡Œæœªæ‰§è¡Œçš„è¿ç§»
            executed_count = 0
            for migration_file in migration_files:
                if migration_file not in executed_migrations:
                    if self.execute_migration(migration_file):
                        executed_count += 1
            
            logger.info(f"è¿ç§»å®Œæˆï¼Œå…±æ‰§è¡Œ {executed_count} ä¸ªè¿ç§»æ–‡ä»¶")
            return executed_count
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œè¿ç§»å¤±è´¥: {str(e)}")
            raise
    
    def export_schema(self, output_file=None):
        """
        å¯¼å‡ºæ•°æ®åº“æ¶æ„
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›SQLè¯­å¥
            
        Returns:
            str: æ•°æ®åº“æ¶æ„SQLè¯­å¥
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰è¡¨å
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
            tables = cursor.fetchall()
            
            schema_sql = """-- æ•°æ®åº“æ¶æ„å¯¼å‡º
-- å¯¼å‡ºæ—¶é—´: {}\n\n""".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
            
            # å¯¼å‡ºæ¯ä¸ªè¡¨çš„åˆ›å»ºè¯­å¥
            for table in tables:
                table_name = table[0]
                cursor.execute(f"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}'")
                create_sql = cursor.fetchone()[0]
                schema_sql += f"\n-- åˆ›å»ºè¡¨ {table_name}\n"
                schema_sql += create_sql + ";\n\n"
            
            # å¯¼å‡ºç´¢å¼•
            cursor.execute("SELECT name, sql FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%'")
            indexes = cursor.fetchall()
            
            for index in indexes:
                index_name, create_sql = index
                schema_sql += f"\n-- åˆ›å»ºç´¢å¼• {index_name}\n"
                schema_sql += create_sql + ";\n\n"
            
            # è¾“å‡ºåˆ°æ–‡ä»¶
            if output_file:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(schema_sql)
                logger.info(f"æ•°æ®åº“æ¶æ„å¯¼å‡ºæˆåŠŸ: {output_file}")
            
            return schema_sql
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºæ•°æ®åº“æ¶æ„å¤±è´¥: {str(e)}")
            raise
        finally:
            if 'conn' in locals():
                conn.close()
    
    def optimize_database(self):
        """ä¼˜åŒ–æ•°æ®åº“æ€§èƒ½"""
        logger.info("å¼€å§‹ä¼˜åŒ–æ•°æ®åº“...")
        
        try:
            conn = self.get_connection()
            conn.execute("VACUUM")
            conn.commit()
            logger.info("æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"æ•°æ®åº“ä¼˜åŒ–å¤±è´¥: {str(e)}")
            raise
        finally:
            if 'conn' in locals():
                conn.close()


# æä¾›ä¾¿æ·çš„æ•°æ®åº“åˆå§‹åŒ–å‡½æ•°
def init_database(db_path):
    """
    åˆå§‹åŒ–æ•°æ®åº“çš„ä¾¿æ·å‡½æ•°
    
    Args:
        db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    """
    migration = DBMigration(db_path)
    migration.initialize_database()
    migration.insert_initial_data()
    migration.optimize_database()
    logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {db_path}")


def run_migrations(db_path):
    """
    æ‰§è¡Œæ•°æ®åº“è¿ç§»çš„ä¾¿æ·å‡½æ•°
    
    Args:
        db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    """
    migration = DBMigration(db_path)
    migration.migrate_all()
    logger.info(f"æ•°æ®åº“è¿ç§»å®Œæˆ: {db_path}")