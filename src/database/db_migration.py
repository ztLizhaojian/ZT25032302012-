# æ•°æ®åº“è¿ç§»å·¥å…·
import json
import os
import sqlite3
import logging
from datetime import datetime

from src.utils.logger import get_logger, log_error, handle_errors, DatabaseError

# è¿ç§»ç›¸å…³çš„å¼‚å¸¸ç±»
class MigrationError(DatabaseError):
    """æ•°æ®åº“è¿ç§»å¼‚å¸¸"""
    def __init__(self, message: str, migration_id: str = None, original_exception: Exception = None):
        self.migration_id = migration_id
        if migration_id:
            message = f"è¿ç§» {migration_id} å¤±è´¥: {message}"
        super().__init__(message, error_code=500, original_exception=original_exception)
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.utils.security import hash_password

# å®šä¹‰è¿ç§»è®°å½•è¡¨å
MIGRATIONS_TABLE = "db_migrations"

# å®šä¹‰ç‰ˆæœ¬åŒ–çš„è¿ç§»è„šæœ¬
VERSION_MIGRATIONS = [
    # ç‰ˆæœ¬ 1 - åˆå§‹æ•°æ®åº“ç»“æ„
    {
        'version': 1,
        'description': 'Initial database structure',
        'upgrade': [
            # è¿™é‡Œæ˜¯åˆå§‹è¡¨ç»“æ„ï¼Œå°†åœ¨initialize_databaseä¸­å®ç°
        ],
        'downgrade': [
            # åˆ é™¤æ‰€æœ‰è¡¨ï¼ˆæŒ‰å¤–é”®ä¾èµ–å…³ç³»å€’åºï¼‰
            'DROP TABLE IF EXISTS transaction_drafts',
            'DROP TABLE IF EXISTS attachments',
            'DROP TABLE IF EXISTS budgets',
            'DROP TABLE IF EXISTS transactions',
            'DROP TABLE IF EXISTS operation_logs',
            'DROP TABLE IF EXISTS system_configs',
            'DROP TABLE IF EXISTS categories',
            'DROP TABLE IF EXISTS accounts',
            'DROP TABLE IF EXISTS users',
            'DROP TABLE IF EXISTS db_migrations'
        ]
    },
    # ç‰ˆæœ¬ 2 - æ·»åŠ è´¦æˆ·ä½™é¢å­—æ®µçš„æ›´æ–°è§¦å‘å™¨
    {
        'version': 2,
        'description': 'Add account balance update triggers',
        'upgrade': [
            # åˆ›å»ºæ’å…¥äº¤æ˜“æ—¶æ›´æ–°è´¦æˆ·ä½™é¢çš„è§¦å‘å™¨
            '''
            CREATE TRIGGER IF NOT EXISTS update_account_balance_after_insert
            AFTER INSERT ON transactions
            BEGIN
                UPDATE accounts
                SET balance = CASE
                    WHEN NEW.transaction_type = 'income' THEN balance + NEW.amount
                    WHEN NEW.transaction_type = 'expense' THEN balance - NEW.amount
                    ELSE balance
                END,
                updated_at = CURRENT_TIMESTAMP
                WHERE id = NEW.account_id;
            END
            ''',
            # åˆ›å»ºæ›´æ–°äº¤æ˜“æ—¶æ›´æ–°è´¦æˆ·ä½™é¢çš„è§¦å‘å™¨
            '''
            CREATE TRIGGER IF NOT EXISTS update_account_balance_after_update
            AFTER UPDATE ON transactions
            BEGIN
                -- å…ˆæ¢å¤æ—§äº¤æ˜“å¯¹è´¦æˆ·ä½™é¢çš„å½±å“
                UPDATE accounts
                SET balance = CASE
                    WHEN OLD.transaction_type = 'income' THEN balance - OLD.amount
                    WHEN OLD.transaction_type = 'expense' THEN balance + OLD.amount
                    ELSE balance
                END
                WHERE id = OLD.account_id;
                
                -- å†åº”ç”¨æ–°äº¤æ˜“å¯¹è´¦æˆ·ä½™é¢çš„å½±å“
                UPDATE accounts
                SET balance = CASE
                    WHEN NEW.transaction_type = 'income' THEN balance + NEW.amount
                    WHEN NEW.transaction_type = 'expense' THEN balance - NEW.amount
                    ELSE balance
                END,
                updated_at = CURRENT_TIMESTAMP
                WHERE id = NEW.account_id;
            END
            ''',
            # åˆ›å»ºåˆ é™¤äº¤æ˜“æ—¶æ›´æ–°è´¦æˆ·ä½™é¢çš„è§¦å‘å™¨
            '''
            CREATE TRIGGER IF NOT EXISTS update_account_balance_after_delete
            AFTER DELETE ON transactions
            BEGIN
                UPDATE accounts
                SET balance = CASE
                    WHEN OLD.transaction_type = 'income' THEN balance - OLD.amount
                    WHEN OLD.transaction_type = 'expense' THEN balance + OLD.amount
                    ELSE balance
                END,
                updated_at = CURRENT_TIMESTAMP
                WHERE id = OLD.account_id;
            END
            '''
        ],
        'downgrade': [
            'DROP TRIGGER IF EXISTS update_account_balance_after_insert',
            'DROP TRIGGER IF EXISTS update_account_balance_after_update',
            'DROP TRIGGER IF EXISTS update_account_balance_after_delete'
        ]
    },
    # ç‰ˆæœ¬ 3 - ä¸ºäº¤æ˜“è¡¨æ·»åŠ æ›´å¤šç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
    {
        'version': 3,
        'description': 'Add more indexes for better performance',
        'upgrade': [
            'CREATE INDEX IF NOT EXISTS idx_transactions_created_at ON transactions (created_at)',
            'CREATE INDEX IF NOT EXISTS idx_transactions_amount ON transactions (amount)',
            'CREATE INDEX IF NOT EXISTS idx_budgets_period ON budgets (period)',
            'CREATE INDEX IF NOT EXISTS idx_operation_logs_created_at ON operation_logs (created_at)',
            'CREATE INDEX IF NOT EXISTS idx_operation_logs_user_id ON operation_logs (user_id)'
        ],
        'downgrade': [
            'DROP INDEX IF EXISTS idx_transactions_created_at',
            'DROP INDEX IF EXISTS idx_transactions_amount',
            'DROP INDEX IF EXISTS idx_budgets_period',
            'DROP INDEX IF EXISTS idx_operation_logs_created_at',
            'DROP INDEX IF EXISTS idx_operation_logs_user_id'
        ]
    }
]

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    handlers=[
                        logging.FileHandler("db_migration.log"),
                        logging.StreamHandler()
                    ])
logger = logging.getLogger("DBMigration")




class DBMigration:
    """æ•°æ®åº“è¿ç§»ç®¡ç†ç±»"""
    
    def __init__(self, db_path):
        """
        åˆå§‹åŒ–è¿ç§»ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        # ä½¿ç”¨è‡ªå®šä¹‰æ—¥å¿—å‡½æ•°
        self.logger = get_logger('db_migration')
        
        self.db_path = db_path
        self.migrations_dir = os.path.join(os.path.dirname(db_path), "migrations")
        self.migration_history = os.path.join(self.migrations_dir, "history.json")
        
        try:
            # ç¡®ä¿è¿ç§»ç›®å½•å­˜åœ¨
            if not os.path.exists(self.migrations_dir):
                os.makedirs(self.migrations_dir)
                self.logger.info(f"åˆ›å»ºè¿ç§»ç›®å½•: {self.migrations_dir}")
            
            # ç¡®ä¿è¿ç§»å†å²æ–‡ä»¶å­˜åœ¨ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            if not os.path.exists(self.migration_history):
                with open(self.migration_history, 'w', encoding='utf-8') as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
                    self.logger.info(f"åˆ›å»ºè¿ç§»å†å²æ–‡ä»¶: {self.migration_history}")
        except Exception as e:
            raise DatabaseError(f"åˆå§‹åŒ–è¿ç§»ç®¡ç†å™¨å¤±è´¥: {str(e)}")
        
        # ç¡®ä¿æ•°æ®åº“ä¸­çš„è¿ç§»è®°å½•è¡¨å­˜åœ¨
        self._ensure_migrations_table()
    
    @handle_errors('db_migration')
    def get_connection(self):
        """
        è·å–æ•°æ®åº“è¿æ¥
        
        Returns:
            sqlite3.Connection: æ•°æ®åº“è¿æ¥å¯¹è±¡
            
        Raises:
            DatabaseError: æ•°æ®åº“è¿æ¥å¤±è´¥æ—¶æŠ›å‡º
        """
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute("PRAGMA foreign_keys = ON")
            return conn
        except sqlite3.Error as e:
            error_msg = f"è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            raise DatabaseError(error_msg)
    
    def _ensure_migrations_table(self):
        """
        ç¡®ä¿è¿ç§»è®°å½•è¡¨å­˜åœ¨
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # åˆ›å»ºè¿ç§»è®°å½•è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS {} (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                version INTEGER NOT NULL UNIQUE,
                description TEXT NOT NULL,
                applied_at TEXT NOT NULL,
                migration_data TEXT
            )
            '''.format(MIGRATIONS_TABLE))
            
            conn.commit()
            conn.close()
            logger.info("è¿ç§»è®°å½•è¡¨æ£€æŸ¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºè¿ç§»è®°å½•è¡¨å¤±è´¥: {str(e)}")
            
    def _add_transaction_indexes(self, cursor):
        """
        ä¸ºtransactionsè¡¨æ·»åŠ ç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
        
        Args:
            cursor: æ•°æ®åº“æ¸¸æ ‡å¯¹è±¡
        """
        try:
            # ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µæ·»åŠ ç´¢å¼•
            # æŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢çš„ç´¢å¼•
            cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_transactions_date 
            ON transactions(transaction_date)
            """)
            
            # æŒ‰è´¦æˆ·æŸ¥è¯¢çš„ç´¢å¼•
            cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_transactions_account 
            ON transactions(account_id)
            """)
            
            # æŒ‰åˆ†ç±»æŸ¥è¯¢çš„ç´¢å¼•
            cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_transactions_category 
            ON transactions(category_id)
            """)
            
            # æŒ‰äº¤æ˜“ç±»å‹æŸ¥è¯¢çš„ç´¢å¼•
            cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_transactions_type 
            ON transactions(transaction_type)
            """)
            
            # å¤åˆç´¢å¼•ï¼šæŒ‰æ—¥æœŸå’Œè´¦æˆ·æŸ¥è¯¢ï¼ˆå¸¸ç”¨äºæŠ¥è¡¨ï¼‰
            cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_transactions_date_account 
            ON transactions(transaction_date, account_id)
            """)
            
            # å¤åˆç´¢å¼•ï¼šæŒ‰æ—¥æœŸå’Œåˆ†ç±»æŸ¥è¯¢ï¼ˆå¸¸ç”¨äºæŠ¥è¡¨ï¼‰
            cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_transactions_date_category 
            ON transactions(transaction_date, category_id)
            """)
            
        except Exception as e:
            logger.error(f"æ·»åŠ äº¤æ˜“è¡¨ç´¢å¼•å¤±è´¥: {str(e)}")
    
    def get_current_version(self) -> int:
        """
        è·å–å½“å‰æ•°æ®åº“ç‰ˆæœ¬
        
        Returns:
            å½“å‰æ•°æ®åº“ç‰ˆæœ¬å·
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¿ç§»è®°å½•è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute('''
            SELECT name FROM sqlite_master WHERE type='table' AND name=?
            ''', (MIGRATIONS_TABLE,))
            
            if not cursor.fetchone():
                conn.close()
                return 0
            
            # è·å–æœ€å¤§ç‰ˆæœ¬å·
            cursor.execute(f"SELECT MAX(version) FROM {MIGRATIONS_TABLE}")
            result = cursor.fetchone()
            conn.close()
            
            return result[0] if result[0] is not None else 0
            
        except Exception as e:
            logger.error(f"è·å–å½“å‰æ•°æ®åº“ç‰ˆæœ¬å¤±è´¥: {str(e)}")
            return 0
    
    def get_latest_version(self) -> int:
        """
        è·å–æœ€æ–°çš„è¿ç§»ç‰ˆæœ¬
        
        Returns:
            æœ€æ–°çš„ç‰ˆæœ¬å·
        """
        if not VERSION_MIGRATIONS:
            return 0
        return max(migration['version'] for migration in VERSION_MIGRATIONS)
    
    @handle_errors('db_migration', fallback_return=[])
    def get_migration_history(self):
        """
        è·å–å·²æ‰§è¡Œçš„è¿ç§»è®°å½•
        
        Returns:
            list: è¿ç§»å†å²è®°å½•åˆ—è¡¨
        """
        try:
            with open(self.migration_history, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError) as e:
            error_msg = f"è¯»å–è¿ç§»å†å²å¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return []
    
    @handle_errors('db_migration')
    def save_migration_history(self, history):
        """
        ä¿å­˜è¿ç§»å†å²
        
        Args:
            history: è¿ç§»å†å²è®°å½•åˆ—è¡¨
            
        Raises:
            DatabaseError: ä¿å­˜å¤±è´¥æ—¶æŠ›å‡º
        """
        try:
            with open(self.migration_history, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
                self.logger.info(f"ä¿å­˜è¿ç§»å†å²æˆåŠŸ")
        except IOError as e:
            error_msg = f"ä¿å­˜è¿ç§»å†å²å¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            raise DatabaseError(error_msg)
    
    def initialize_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“ï¼Œåˆ›å»ºå¿…è¦çš„è¡¨ç»“æ„"""
        logger.info("å¼€å§‹åˆå§‹åŒ–æ•°æ®åº“...")
        
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # é¦–å…ˆç¡®ä¿è¿ç§»è¡¨å­˜åœ¨
            self._ensure_migrations_table()
            
            # 1. åˆ›å»ºç”¨æˆ·è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT NOT NULL UNIQUE,
                password TEXT NOT NULL,
                fullname TEXT NOT NULL,
                email TEXT,
                role TEXT DEFAULT 'user',
                status TEXT DEFAULT 'active',
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                last_login TEXT
            )
            """)
            logger.info("åˆ›å»ºusersè¡¨æˆåŠŸ")
            
            # 2. åˆ›å»ºè´¦æˆ·è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS accounts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                account_type TEXT NOT NULL,
                currency TEXT DEFAULT 'CNY',
                balance REAL DEFAULT 0.0,
                description TEXT,
                status TEXT DEFAULT 'active',
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
            """)
            logger.info("åˆ›å»ºaccountsè¡¨æˆåŠŸ")
            
            # 3. åˆ›å»ºåˆ†ç±»è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS categories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                category_type TEXT NOT NULL,
                parent_id INTEGER,
                icon TEXT DEFAULT 'default',
                color TEXT DEFAULT '#007bff',
                description TEXT,
                is_system INTEGER DEFAULT 0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (parent_id) REFERENCES categories(id)
            )
            """)
            logger.info("åˆ›å»ºcategoriesè¡¨æˆåŠŸ")
            
            # 4. åˆ›å»ºäº¤æ˜“è®°å½•è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS transactions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                transaction_type TEXT NOT NULL,
                amount REAL NOT NULL,
                account_id INTEGER NOT NULL,
                category_id INTEGER NOT NULL,
                transaction_date TEXT NOT NULL,
                description TEXT,
                receipt_number TEXT,
                payment_method TEXT,
                created_by INTEGER,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                reconciliation_flag INTEGER DEFAULT 0,
                FOREIGN KEY (account_id) REFERENCES accounts(id),
                FOREIGN KEY (category_id) REFERENCES categories(id),
                FOREIGN KEY (created_by) REFERENCES users(id)
            )
            """)
            logger.info("åˆ›å»ºtransactionsè¡¨æˆåŠŸ")
            
            # ä¸ºtransactionsè¡¨æ·»åŠ ç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            self._add_transaction_indexes(cursor)
            logger.info("ä¸ºtransactionsè¡¨æ·»åŠ ç´¢å¼•æˆåŠŸ")
            
            # 5. åˆ›å»ºé¢„ç®—è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS budgets (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category_id INTEGER NOT NULL,
                amount REAL NOT NULL,
                period TEXT NOT NULL,
                start_date TEXT NOT NULL,
                end_date TEXT NOT NULL,
                description TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (category_id) REFERENCES categories(id)
            )
            """)
            logger.info("åˆ›å»ºbudgetsè¡¨æˆåŠŸ")
            
            # 6. åˆ›å»ºé™„ä»¶è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS attachments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                transaction_id INTEGER NOT NULL,
                file_path TEXT NOT NULL,
                file_name TEXT NOT NULL,
                file_size INTEGER,
                file_type TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (transaction_id) REFERENCES transactions(id)
            )
            """)
            logger.info("åˆ›å»ºattachmentsè¡¨æˆåŠŸ")
            
            # 7. åˆ›å»ºç³»ç»Ÿé…ç½®è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS system_configs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                config_key TEXT NOT NULL UNIQUE,
                config_value TEXT,
                config_type TEXT DEFAULT 'string',
                description TEXT,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
            """)
            logger.info("åˆ›å»ºsystem_configsè¡¨æˆåŠŸ")
            
            # 8. åˆ›å»ºæ“ä½œæ—¥å¿—è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS operation_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                operation_type TEXT NOT NULL,
                operation_desc TEXT,
                operation_table TEXT,
                operation_data TEXT,
                ip_address TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(id)
            )
            """)
            logger.info("åˆ›å»ºoperation_logsè¡¨æˆåŠŸ")
            
            # 9. åˆ›å»ºäº¤æ˜“è‰ç¨¿è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS transaction_drafts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER NOT NULL,
                transaction_type TEXT,
                account_id INTEGER,
                category_id INTEGER,
                amount REAL,
                transaction_date TEXT,
                description TEXT,
                reference_number TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(id),
                FOREIGN KEY (account_id) REFERENCES accounts(id),
                FOREIGN KEY (category_id) REFERENCES categories(id)
            )
            """)
            logger.info("åˆ›å»ºtransaction_draftsè¡¨æˆåŠŸ")
            
            # 10. åˆ›å»ºå¯¹è´¦æ—¥å¿—è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS reconciliation_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                account_id INTEGER,
                start_date TEXT,
                end_date TEXT,
                actual_balance REAL,
                theoretical_balance REAL,
                difference REAL,
                is_balanced INTEGER,
                reconciled_by INTEGER,
                reconciled_at TEXT,
                FOREIGN KEY (account_id) REFERENCES accounts (id),
                FOREIGN KEY (reconciled_by) REFERENCES users (id)
            )
            """)
            logger.info("åˆ›å»ºreconciliation_logsè¡¨æˆåŠŸ")
            
            # 11. åˆ›å»ºè½¬è´¦è®°å½•è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS transfer_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                from_transaction_id INTEGER,
                to_transaction_id INTEGER,
                amount REAL,
                transfer_date TEXT,
                FOREIGN KEY (from_transaction_id) REFERENCES transactions (id),
                FOREIGN KEY (to_transaction_id) REFERENCES transactions (id)
            )
            """)
            logger.info("åˆ›å»ºtransfer_recordsè¡¨æˆåŠŸ")
            
            # 12. åˆ›å»ºç”¨æˆ·æƒé™è¡¨
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_permissions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                resource_type TEXT,
                resource_id INTEGER,
                permission TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (id)
            )
            """)
            logger.info("åˆ›å»ºuser_permissionsè¡¨æˆåŠŸ")
            
            # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_transactions_date ON transactions(transaction_date)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_transactions_account ON transactions(account_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_transactions_category ON transactions(category_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_transactions_type ON transactions(transaction_type)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_users_username ON users(username)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_accounts_status ON accounts(status)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_categories_type ON categories(category_type)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_drafts_user ON transaction_drafts(user_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_drafts_created ON transaction_drafts(created_at)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_drafts_updated ON transaction_drafts(updated_at)")
            logger.info("åˆ›å»ºç´¢å¼•æˆåŠŸ")
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            
            # è®°å½•åˆå§‹ç‰ˆæœ¬
            self._record_version(1, 'Initial database structure')
            
            logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            if 'conn' in locals():
                conn.rollback()
            raise
        finally:
            if 'conn' in locals():
                conn.close()
    
    def _record_version(self, version: int, description: str):
        """
        è®°å½•ç‰ˆæœ¬ä¿¡æ¯åˆ°è¿ç§»è¡¨
        
        Args:
            version: ç‰ˆæœ¬å·
            description: æè¿°
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            migration_info = {
                'version': version,
                'description': description,
                'applied_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'migration_data': json.dumps({
                    'type': 'upgrade',
                    'timestamp': datetime.now().isoformat()
                })
            }
            
            # æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦å·²å­˜åœ¨
            cursor.execute(f"SELECT id FROM {MIGRATIONS_TABLE} WHERE version = ?", (version,))
            if not cursor.fetchone():
                cursor.execute(
                    f"INSERT INTO {MIGRATIONS_TABLE} (version, description, applied_at, migration_data) VALUES (?, ?, ?, ?)",
                    (migration_info['version'], migration_info['description'], 
                     migration_info['applied_at'], migration_info['migration_data'])
                )
                conn.commit()
            
            conn.close()
            
        except Exception as e:
            logger.error(f"è®°å½•ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {str(e)}")
            if 'conn' in locals():
                conn.rollback()
                conn.close()
    
    def insert_initial_data(self):
        """æ’å…¥åˆå§‹æ•°æ®"""
        logger.info("å¼€å§‹æ’å…¥åˆå§‹æ•°æ®...")
        
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # 1. æ£€æŸ¥æ˜¯å¦å·²æœ‰ç®¡ç†å‘˜ç”¨æˆ·
            cursor.execute("SELECT COUNT(*) FROM users WHERE role = 'admin'")
            if cursor.fetchone()[0] == 0:
                # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·ï¼Œä½¿ç”¨å“ˆå¸Œå¤„ç†çš„å¯†ç 
                admin_password = 'admin123'
                hashed_password = hash_password(admin_password)
                cursor.execute(
                    "INSERT INTO users (username, password, fullname, email, role) VALUES (?, ?, ?, ?, ?)",
                    ('admin', hashed_password, 'ç³»ç»Ÿç®¡ç†å‘˜', 'admin@example.com', 'admin')
                )
                logger.info("åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·æˆåŠŸ")
            
            # 2. æ£€æŸ¥æ˜¯å¦å·²æœ‰é»˜è®¤è´¦æˆ·
            cursor.execute("SELECT COUNT(*) FROM accounts")
            if cursor.fetchone()[0] == 0:
                # åˆ›å»ºé»˜è®¤è´¦æˆ·
                default_accounts = [
                    ('ç°é‡‘è´¦æˆ·', 'asset', 'CNY', 0.0, 'ä¸»è¦ç”¨äºè®°å½•ç°é‡‘æ”¶æ”¯', 'active'),
                    ('é“¶è¡Œå­˜æ¬¾', 'asset', 'CNY', 0.0, 'ä¸»è¦ç”¨äºè®°å½•é“¶è¡Œè´¦æˆ·æ”¶æ”¯', 'active'),
                    ('åº”æ”¶è´¦æ¬¾', 'asset', 'CNY', 0.0, 'è®°å½•å®¢æˆ·æ¬ æ¬¾', 'active'),
                    ('åº”ä»˜è´¦æ¬¾', 'liability', 'CNY', 0.0, 'è®°å½•æ¬ ä¾›åº”å•†æ¬¾é¡¹', 'active'),
                    ('è‚¡æœ¬', 'equity', 'CNY', 0.0, 'è®°å½•å…¬å¸æ³¨å†Œèµ„æœ¬', 'active')
                ]
                
                for account in default_accounts:
                    cursor.execute(
                        "INSERT INTO accounts (name, account_type, currency, balance, description, status) VALUES (?, ?, ?, ?, ?, ?)",
                        account
                    )
                logger.info("åˆ›å»ºé»˜è®¤è´¦æˆ·æˆåŠŸ")
            
            # 3. æ£€æŸ¥æ˜¯å¦å·²æœ‰é»˜è®¤åˆ†ç±»
            cursor.execute("SELECT COUNT(*) FROM categories")
            if cursor.fetchone()[0] == 0:
                # åˆ›å»ºé»˜è®¤æ”¶å…¥åˆ†ç±»
                income_categories = [
                    ('ä¸»è¥ä¸šåŠ¡æ”¶å…¥', 'income', None, 'ğŸ’°', '#28a745', 'default', 'é”€å”®å•†å“æˆ–æä¾›æœåŠ¡çš„æ”¶å…¥', 1),
                    ('å…¶ä»–ä¸šåŠ¡æ”¶å…¥', 'income', None, 'ğŸ’µ', '#20c997', 'default', 'éä¸»è¥ä¸šåŠ¡çš„æ”¶å…¥', 1),
                    ('æŠ•èµ„æ”¶ç›Š', 'income', None, 'ğŸ“ˆ', '#6f42c1', 'default', 'æŠ•èµ„è·å¾—çš„æ”¶ç›Š', 1),
                    ('è¥ä¸šå¤–æ”¶å…¥', 'income', None, 'ğŸ', '#ffc107', 'default', 'ä¸ç”Ÿäº§ç»è¥æ— ç›´æ¥å…³ç³»çš„æ”¶å…¥', 1)
                ]
                
                for category in income_categories:
                    cursor.execute(
                        "INSERT INTO categories (name, category_type, parent_id, icon, color, description, is_system) VALUES (?, ?, ?, ?, ?, ?, ?)",
                        category[:-1]  # å»æ‰æœ€åä¸€ä¸ªå…ƒç´ ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦'default'å­—æ®µ
                    )
                
                # åˆ›å»ºé»˜è®¤æ”¯å‡ºåˆ†ç±»
                expense_categories = [
                    ('ä¸»è¥ä¸šåŠ¡æˆæœ¬', 'expense', None, 'ğŸ“¦', '#dc3545', 'default', 'é”€å”®å•†å“æˆ–æä¾›æœåŠ¡çš„æˆæœ¬', 1),
                    ('é”€å”®è´¹ç”¨', 'expense', None, 'ğŸ¢', '#fd7e14', 'default', 'é”€å”®è¿‡ç¨‹ä¸­å‘ç”Ÿçš„å„é¡¹è´¹ç”¨', 1),
                    ('ç®¡ç†è´¹ç”¨', 'expense', None, 'âš™ï¸', '#17a2b8', 'default', 'ä¼ä¸šç®¡ç†éƒ¨é—¨å‘ç”Ÿçš„è´¹ç”¨', 1),
                    ('è´¢åŠ¡è´¹ç”¨', 'expense', None, 'ğŸ’¸', '#6c757d', 'default', 'ç­¹é›†ç”Ÿäº§ç»è¥æ‰€éœ€èµ„é‡‘ç­‰å‘ç”Ÿçš„è´¹ç”¨', 1),
                    ('è¥ä¸šå¤–æ”¯å‡º', 'expense', None, 'âŒ', '#343a40', 'default', 'ä¸ç”Ÿäº§ç»è¥æ— ç›´æ¥å…³ç³»çš„æ”¯å‡º', 1)
                ]
                
                for category in expense_categories:
                    cursor.execute(
                        "INSERT INTO categories (name, category_type, parent_id, icon, color, description, is_system) VALUES (?, ?, ?, ?, ?, ?, ?)",
                        category[:-1]  # å»æ‰æœ€åä¸€ä¸ªå…ƒç´ ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦'default'å­—æ®µ
                    )
                
                logger.info("åˆ›å»ºé»˜è®¤åˆ†ç±»æˆåŠŸ")
            
            # 4. æ£€æŸ¥æ˜¯å¦å·²æœ‰ç³»ç»Ÿé…ç½®
            cursor.execute("SELECT COUNT(*) FROM system_configs")
            if cursor.fetchone()[0] == 0:
                # æ’å…¥é»˜è®¤ç³»ç»Ÿé…ç½®
                default_configs = [
                    ('company_name', 'æœªè®¾ç½®å…¬å¸åç§°', 'string', 'å…¬å¸åç§°'),
                    ('currency', 'CNY', 'string', 'é»˜è®¤è´§å¸'),
                    ('decimal_places', '2', 'integer', 'å°æ•°ä½æ•°'),
                    ('auto_backup', 'true', 'boolean', 'è‡ªåŠ¨å¤‡ä»½'),
                    ('backup_frequency', 'daily', 'string', 'å¤‡ä»½é¢‘ç‡'),
                    ('language', 'zh_CN', 'string', 'ç³»ç»Ÿè¯­è¨€'),
                    ('theme', 'light', 'string', 'ç³»ç»Ÿä¸»é¢˜'),
                    ('default_period', 'month', 'string', 'é»˜è®¤æŠ¥è¡¨å‘¨æœŸ'),
                    ('data_retention_days', '365', 'integer', 'æ•°æ®ä¿ç•™å¤©æ•°'),
                    ('log_level', 'INFO', 'string', 'æ—¥å¿—çº§åˆ«')
                ]
                
                for config in default_configs:
                    cursor.execute(
                        "INSERT INTO system_configs (config_key, config_value, config_type, description) VALUES (?, ?, ?, ?)",
                        config
                    )
                
                logger.info("åˆ›å»ºé»˜è®¤ç³»ç»Ÿé…ç½®æˆåŠŸ")
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            logger.info("åˆå§‹æ•°æ®æ’å…¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ’å…¥åˆå§‹æ•°æ®å¤±è´¥: {str(e)}")
            if 'conn' in locals():
                conn.rollback()
            raise
        finally:
            if 'conn' in locals():
                conn.close()
    
    def create_migration(self, migration_name):
        """
        åˆ›å»ºæ–°çš„è¿ç§»æ–‡ä»¶
        
        Args:
            migration_name: è¿ç§»åç§°
            
        Returns:
            str: è¿ç§»æ–‡ä»¶è·¯å¾„
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            migration_file = f"{timestamp}_{migration_name}.sql"
            migration_path = os.path.join(self.migrations_dir, migration_file)
            
            # åˆ›å»ºç©ºçš„è¿ç§»æ–‡ä»¶
            with open(migration_path, 'w', encoding='utf-8') as f:
                f.write(f"-- è¿ç§»æ–‡ä»¶: {migration_name}\n")
                f.write(f"-- åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("-- åœ¨æ­¤å¤„ç¼–å†™SQLè¯­å¥\n")
            
            logger.info(f"åˆ›å»ºè¿ç§»æ–‡ä»¶æˆåŠŸ: {migration_file}")
            return migration_path
            
        except Exception as e:
            logger.error(f"åˆ›å»ºè¿ç§»æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise
    
    @handle_errors('db_migration')
    def execute_migration(self, migration_file):
        """
        æ‰§è¡ŒæŒ‡å®šçš„è¿ç§»æ–‡ä»¶
        
        Args:
            migration_file: è¿ç§»æ–‡ä»¶åç§°
            
        Returns:
            bool: è¿ç§»æ˜¯å¦æˆåŠŸæ‰§è¡Œ
            
        Raises:
            MigrationError: è¿ç§»æ‰§è¡Œå¤±è´¥æ—¶æŠ›å‡º
            DatabaseError: æ•°æ®åº“æ“ä½œå¤±è´¥æ—¶æŠ›å‡º
        """
        try:
            # æ£€æŸ¥è¿ç§»æ˜¯å¦å·²æ‰§è¡Œ
            history = self.get_migration_history()
            if migration_file in [m['file'] for m in history]:
                self.logger.warning(f"è¿ç§»æ–‡ä»¶å·²æ‰§è¡Œ: {migration_file}")
                return False
            
            # è¯»å–è¿ç§»æ–‡ä»¶
            migration_path = os.path.join(self.migrations_dir, migration_file)
            if not os.path.exists(migration_path):
                self.logger.error(f"è¿ç§»æ–‡ä»¶ä¸å­˜åœ¨: {migration_file}")
                raise MigrationError(f"è¿ç§»æ–‡ä»¶ä¸å­˜åœ¨: {migration_file}")
            
            with open(migration_path, 'r', encoding='utf-8') as f:
                sql_statements = f.read()
            
            # æ‰§è¡ŒSQLè¯­å¥
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # åˆ†å‰²å¹¶æ‰§è¡Œå¤šä¸ªSQLè¯­å¥
            for statement in sql_statements.split(';'):
                statement = statement.strip()
                if statement and not statement.startswith('--'):
                    cursor.execute(statement)
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            
            # æ›´æ–°è¿ç§»å†å²
            migration_record = {
                'file': migration_file,
                'executed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            history.append(migration_record)
            self.save_migration_history(history)
            
            self.logger.info(f"è¿ç§»æ–‡ä»¶æ‰§è¡ŒæˆåŠŸ: {migration_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œè¿ç§»æ–‡ä»¶å¤±è´¥: {str(e)}")
            if 'conn' in locals():
                conn.rollback()
            if isinstance(e, (MigrationError, DatabaseError)):
                raise
            raise MigrationError(f"è¿ç§»æ‰§è¡Œå¤±è´¥: {str(e)}")
        finally:
            if 'conn' in locals():
                conn.close()
    
    @handle_errors
    def migrate_all(self):
        """æ‰§è¡Œæ‰€æœ‰æœªæ‰§è¡Œçš„è¿ç§»æ–‡ä»¶å’Œç‰ˆæœ¬å‡çº§
        
        Raises:
            MigrationError: è¿ç§»æ‰§è¡Œå¤±è´¥æ—¶æŠ›å‡º
            DatabaseError: æ•°æ®åº“æ“ä½œå¤±è´¥æ—¶æŠ›å‡º
        """
        self.logger.info("å¼€å§‹æ‰§è¡Œæ‰€æœ‰æœªæ‰§è¡Œçš„è¿ç§»...")
        
        # é¦–å…ˆæ‰§è¡Œç‰ˆæœ¬åŒ–è¿ç§»
        current_version = self.get_current_version()
        latest_version = self.get_latest_version()
        
        if current_version < latest_version:
            self.logger.info(f"æ‰§è¡Œç‰ˆæœ¬å‡çº§: {current_version} -> {latest_version}")
            self.upgrade(current_version, latest_version)
        
        # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šç»§ç»­æ‰§è¡Œæ–‡ä»¶ç³»ç»Ÿä¸­çš„è¿ç§»æ–‡ä»¶
        history = self.get_migration_history()
        executed_migrations = [m['file'] for m in history]
        
        migration_files = [f for f in os.listdir(self.migrations_dir) 
                         if f.endswith('.sql') and f != 'init.sql']
        
        migration_files.sort()
        
        executed_count = 0
        for migration_file in migration_files:
            if migration_file not in executed_migrations:
                if self.execute_migration(migration_file):
                    executed_count += 1
        
        self.logger.info(f"è¿ç§»å®Œæˆï¼Œå½“å‰ç‰ˆæœ¬: {self.get_current_version()}, æ‰§è¡Œæ–‡ä»¶è¿ç§»: {executed_count} ä¸ª")
        return executed_count
    
    @handle_errors
    def upgrade(self, from_version: int, to_version: int) -> Dict[str, Any]:
        """
        å‡çº§æ•°æ®åº“åˆ°æŒ‡å®šç‰ˆæœ¬
        
        Args:
            from_version: èµ·å§‹ç‰ˆæœ¬
            to_version: ç›®æ ‡ç‰ˆæœ¬
            
        Returns:
            å‡çº§ç»“æœä¿¡æ¯
            
        Raises:
            MigrationError: è¿ç§»æ‰§è¡Œå¤±è´¥æ—¶æŠ›å‡º
            DatabaseError: æ•°æ®åº“æ“ä½œå¤±è´¥æ—¶æŠ›å‡º
        """
        self.logger.info(f"å¼€å§‹å‡çº§æ•°æ®åº“: {from_version} -> {to_version}")
        
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            applied_migrations = []
            
            # æŒ‰ç‰ˆæœ¬é¡ºåºæ‰§è¡Œå‡çº§
            for migration in sorted(VERSION_MIGRATIONS, key=lambda x: x['version']):
                if from_version < migration['version'] <= to_version:
                    self.logger.info(f"æ‰§è¡Œå‡çº§åˆ°ç‰ˆæœ¬ {migration['version']}: {migration['description']}")
                    
                    # æ‰§è¡Œæ¯ä¸ªSQLè¯­å¥
                    for sql in migration['upgrade']:
                        try:
                            cursor.execute(sql)
                            self.logger.debug(f"æ‰§è¡ŒSQLæˆåŠŸ: {sql[:50]}...")
                        except Exception as e:
                            self.logger.error(f"æ‰§è¡ŒSQLå¤±è´¥: {sql[:50]}... - {str(e)}")
                            raise
                    
                    applied_migrations.append(migration['version'])
            
            conn.commit()
            conn.close()
            
            # è®°å½•æ‰€æœ‰åº”ç”¨çš„ç‰ˆæœ¬
            for version in applied_migrations:
                migration = next(m for m in VERSION_MIGRATIONS if m['version'] == version)
                self._record_version(version, migration['description'])
            
            self.logger.info(f"æ•°æ®åº“å‡çº§æˆåŠŸ: {from_version} -> {to_version}, åº”ç”¨äº† {len(applied_migrations)} ä¸ªè¿ç§»")
            
            return {
                'success': True,
                'from_version': from_version,
                'to_version': to_version,
                'applied_migrations': applied_migrations
            }
            
        except Exception as e:
            if 'conn' in locals():
                conn.rollback()
                conn.close()
            self.logger.error(f"æ•°æ®åº“å‡çº§å¤±è´¥: {str(e)}")
            raise
    
    @handle_errors
    def downgrade(self, from_version: int, to_version: int) -> Dict[str, Any]:
        """
        é™çº§æ•°æ®åº“ç‰ˆæœ¬
        
        Args:
            from_version: å½“å‰ç‰ˆæœ¬
            to_version: ç›®æ ‡ç‰ˆæœ¬
            
        Returns:
            Dict: é™çº§ç»“æœä¿¡æ¯
            
        Raises:
            MigrationError: è¿ç§»æ‰§è¡Œå¤±è´¥æ—¶æŠ›å‡º
            DatabaseError: æ•°æ®åº“æ“ä½œå¤±è´¥æ—¶æŠ›å‡º
            ValueError: æ— æ•ˆçš„ç‰ˆæœ¬å·èŒƒå›´æ—¶æŠ›å‡º
        """
        self.logger.info(f"å¼€å§‹é™çº§æ•°æ®åº“: {from_version} -> {to_version}")
        
        # éªŒè¯ç‰ˆæœ¬å·
        if to_version < 0 or from_version < to_version:
            raise ValueError(f"æ— æ•ˆçš„ç‰ˆæœ¬å·èŒƒå›´: {from_version} -> {to_version}")
        
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            conn.execute("PRAGMA foreign_keys = OFF")  # é™çº§æ—¶å…³é—­å¤–é”®çº¦æŸ
            
            reverted_migrations = []
            
            # æŒ‰ç‰ˆæœ¬å€’åºæ‰§è¡Œé™çº§
            for migration in sorted(VERSION_MIGRATIONS, key=lambda x: x['version'], reverse=True):
                if to_version < migration['version'] <= from_version:
                    self.logger.info(f"æ‰§è¡Œå›æ»šç‰ˆæœ¬ {migration['version']}: {migration['description']}")
                    
                    # æ‰§è¡Œæ¯ä¸ªå›æ»šSQLè¯­å¥
                    for sql in migration['downgrade']:
                        try:
                            cursor.execute(sql)
                            self.logger.debug(f"æ‰§è¡Œå›æ»šSQLæˆåŠŸ: {sql[:50]}...")
                        except Exception as e:
                            self.logger.warning(f"æ‰§è¡Œå›æ»šSQLå¤±è´¥: {sql[:50]}... - {str(e)}")
                            # é™çº§å¤±è´¥ä¸ä¸­æ–­ï¼Œç»§ç»­å°è¯•å…¶ä»–æ“ä½œ
                            continue
                    
                    # åˆ é™¤è¿ç§»è®°å½•
                    cursor.execute(f"DELETE FROM {MIGRATIONS_TABLE} WHERE version = ?", (migration['version'],))
                    reverted_migrations.append(migration['version'])
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"æ•°æ®åº“é™çº§æˆåŠŸ: {from_version} -> {to_version}, å›æ»šäº† {len(reverted_migrations)} ä¸ªè¿ç§»")
            
            return {
                'success': True,
                'from_version': from_version,
                'to_version': to_version,
                'reverted_migrations': reverted_migrations
            }
            
        except Exception as e:
            if 'conn' in locals():
                conn.rollback()
                conn.close()
            self.logger.error(f"æ•°æ®åº“é™çº§å¤±è´¥: {str(e)}")
            if isinstance(e, (MigrationError, DatabaseError)):
                raise
            raise MigrationError(f"æ•°æ®åº“é™çº§å¤±è´¥: {str(e)}")
    
    def get_migration_history_db(self) -> List[Dict[str, Any]]:
        """
        ä»æ•°æ®åº“è·å–è¿ç§»å†å²è®°å½•
        
        Returns:
            è¿ç§»å†å²è®°å½•åˆ—è¡¨
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¿ç§»è®°å½•è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute('''
            SELECT name FROM sqlite_master WHERE type='table' AND name=?
            ''', (MIGRATIONS_TABLE,))
            
            if not cursor.fetchone():
                conn.close()
                return []
            
            # è·å–æ‰€æœ‰è¿ç§»è®°å½•
            cursor.execute(f"SELECT * FROM {MIGRATIONS_TABLE} ORDER BY version DESC")
            columns = [desc[0] for desc in cursor.description]
            results = []
            
            for row in cursor.fetchall():
                result = dict(zip(columns, row))
                # è§£æJSONæ•°æ®
                if result.get('migration_data'):
                    try:
                        result['migration_data'] = json.loads(result['migration_data'])
                    except:
                        result['migration_data'] = None
                results.append(result)
            
            conn.close()
            return results
            
        except Exception as e:
            logger.error(f"è·å–è¿ç§»å†å²å¤±è´¥: {str(e)}")
            return []
    
    @handle_errors
    def export_schema(self, output_file=None):
        """
        å¯¼å‡ºæ•°æ®åº“æ¶æ„
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›SQLè¯­å¥
            
        Returns:
            str: æ•°æ®åº“æ¶æ„SQLè¯­å¥
            
        Raises:
            DatabaseError: æ•°æ®åº“æ“ä½œå¤±è´¥æ—¶æŠ›å‡º
            IOError: æ–‡ä»¶å†™å…¥å¤±è´¥æ—¶æŠ›å‡º
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰è¡¨å
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
            tables = cursor.fetchall()
            
            schema_sql = """-- æ•°æ®åº“æ¶æ„å¯¼å‡º
-- å¯¼å‡ºæ—¶é—´: {}\n\n""".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
            
            # å¯¼å‡ºæ¯ä¸ªè¡¨çš„åˆ›å»ºè¯­å¥
            for table in tables:
                table_name = table[0]
                cursor.execute(f"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}'")
                create_sql = cursor.fetchone()[0]
                schema_sql += f"\n-- åˆ›å»ºè¡¨ {table_name}\n"
                schema_sql += create_sql + ";\n\n"
            
            # å¯¼å‡ºç´¢å¼•
            cursor.execute("SELECT name, sql FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%'")
            indexes = cursor.fetchall()
            
            for index in indexes:
                index_name, create_sql = index
                schema_sql += f"\n-- åˆ›å»ºç´¢å¼• {index_name}\n"
                schema_sql += create_sql + ";\n\n"
            
            # è¾“å‡ºåˆ°æ–‡ä»¶
            if output_file:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(schema_sql)
                self.logger.info(f"æ•°æ®åº“æ¶æ„å¯¼å‡ºæˆåŠŸ: {output_file}")
            
            return schema_sql
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºæ•°æ®åº“æ¶æ„å¤±è´¥: {str(e)}")
            if isinstance(e, (DatabaseError, IOError)):
                raise
            raise DatabaseError(f"å¯¼å‡ºæ•°æ®åº“æ¶æ„å¤±è´¥: {str(e)}")
        finally:
            if 'conn' in locals():
                conn.close()
    
    def optimize_database(self):
        """ä¼˜åŒ–æ•°æ®åº“æ€§èƒ½"""
        logger.info("å¼€å§‹ä¼˜åŒ–æ•°æ®åº“...")
        
        try:
            conn = self.get_connection()
            conn.execute("VACUUM")
            conn.commit()
            logger.info("æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"æ•°æ®åº“ä¼˜åŒ–å¤±è´¥: {str(e)}")
            raise
        finally:
            if 'conn' in locals():
                conn.close()


# æä¾›ä¾¿æ·çš„æ•°æ®åº“åˆå§‹åŒ–å‡½æ•°


# MigrationManagerç±» - ä¸ºæµ‹è¯•å’Œå¤–éƒ¨è°ƒç”¨æä¾›ç»Ÿä¸€æ¥å£
class MigrationManager:
    """
    æ•°æ®åº“è¿ç§»ç®¡ç†å™¨ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®åº“è¿ç§»æ¥å£
    """
    def __init__(self, db_path_or_manager):
        """
        åˆå§‹åŒ–MigrationManager
        
        Args:
            db_path_or_manager: æ•°æ®åº“æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²æˆ–DatabaseManagerå¯¹è±¡
        """
        # å¤„ç†DatabaseManagerå¯¹è±¡çš„æƒ…å†µ
        if hasattr(db_path_or_manager, 'db_path'):
            # ç¡®ä¿æå–çš„db_pathæ˜¯å­—ç¬¦ä¸²ç±»å‹
            db_path = db_path_or_manager.db_path
            if not isinstance(db_path, str):
                raise TypeError("DatabaseManager.db_pathå¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹")
            self.db_path = db_path
        elif isinstance(db_path_or_manager, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
            self.db_path = db_path_or_manager
        else:
            raise TypeError("å‚æ•°å¿…é¡»æ˜¯æ•°æ®åº“è·¯å¾„å­—ç¬¦ä¸²æˆ–å…·æœ‰db_pathå±æ€§çš„DatabaseManagerå¯¹è±¡")
        
        # åˆ›å»ºDBMigrationå®ä¾‹
        self.migration = DBMigration(self.db_path)
    
    def initialize(self):
        """
        åˆå§‹åŒ–æ•°æ®åº“
        """
        return init_database(self.db_path)
    
    def migrate_all(self):
        """
        æ‰§è¡Œæ‰€æœ‰æœªæ‰§è¡Œçš„è¿ç§»
        """
        return run_migrations(self.db_path)
    
    def migrate_to(self, target_version=None):
        """
        è¿ç§»åˆ°æŒ‡å®šç‰ˆæœ¬
        
        Args:
            target_version: ç›®æ ‡ç‰ˆæœ¬ï¼Œå¦‚æœä¸ºNoneåˆ™è¿ç§»åˆ°æœ€æ–°ç‰ˆæœ¬
            
        Returns:
            è¿ç§»ç»“æœ
        """
        return run_migration(self.db_path, target_version)
    
    def get_current_version(self):
        """
        è·å–å½“å‰æ•°æ®åº“ç‰ˆæœ¬
        
        Returns:
            å½“å‰ç‰ˆæœ¬å·
        """
        return self.migration.get_current_version()
    
    def get_latest_version(self):
        """
        è·å–æœ€æ–°å¯ç”¨ç‰ˆæœ¬
        
        Returns:
            æœ€æ–°ç‰ˆæœ¬å·
        """
        return self.migration.get_latest_version()
    
    def get_history(self):
        """
        è·å–è¿ç§»å†å²
        
        Returns:
            è¿ç§»å†å²è®°å½•åˆ—è¡¨
        """
        return self.migration.get_migration_history_db()
    
    def verify_integrity(self):
        """
        éªŒè¯æ•°æ®åº“å®Œæ•´æ€§
        
        Returns:
            å®Œæ•´æ€§æ£€æŸ¥ç»“æœ
        """
        return verify_database_integrity(self.db_path)

def init_database(db_path):
    """
    åˆå§‹åŒ–æ•°æ®åº“çš„ä¾¿æ·å‡½æ•°
    
    Args:
        db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    """
    migration = DBMigration(db_path)
    migration.initialize_database()
    migration.insert_initial_data()
    migration.optimize_database()
    logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {db_path}")


def run_migrations(db_path):
    """
    æ‰§è¡Œæ•°æ®åº“è¿ç§»çš„ä¾¿æ·å‡½æ•°
    
    Args:
        db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    """
    migration = DBMigration(db_path)
    migration.migrate_all()
    logger.info(f"æ•°æ®åº“è¿ç§»å®Œæˆ: {db_path}")


def run_migration(db_path: str, target_version: int = None) -> Dict[str, Any]:
    """
    è¿è¡Œæ•°æ®åº“è¿ç§»åˆ°æŒ‡å®šç‰ˆæœ¬ï¼ˆå¤–éƒ¨ç»Ÿä¸€æ¥å£ï¼‰
    
    Args:
        db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        target_version: ç›®æ ‡ç‰ˆæœ¬ï¼Œå¦‚æœä¸ºNoneåˆ™è¿ç§»åˆ°æœ€æ–°ç‰ˆæœ¬
        
    Returns:
        è¿ç§»ç»“æœä¿¡æ¯
    """
    try:
        migration = DBMigration(db_path)
        current_version = migration.get_current_version()
        
        # å¦‚æœæœªæŒ‡å®šç›®æ ‡ç‰ˆæœ¬ï¼Œåˆ™è¿ç§»åˆ°æœ€æ–°ç‰ˆæœ¬
        if target_version is None:
            target_version = migration.get_latest_version()
        
        # éªŒè¯ç›®æ ‡ç‰ˆæœ¬
        if target_version < 0 or target_version > migration.get_latest_version():
            raise ValueError(f"æ— æ•ˆçš„ç›®æ ‡ç‰ˆæœ¬: {target_version}")
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ç›®æ ‡ç‰ˆæœ¬
        if current_version == target_version:
            logger.info(f"æ•°æ®åº“å·²ç»æ˜¯ç›®æ ‡ç‰ˆæœ¬: {current_version}")
            return {
                'success': True,
                'current_version': current_version,
                'target_version': target_version,
                'message': f'æ•°æ®åº“å·²ç»æ˜¯ç‰ˆæœ¬ {current_version}'
            }
        
        # æ‰§è¡Œå‡çº§æˆ–é™çº§
        if current_version < target_version:
            result = migration.upgrade(current_version, target_version)
            result['message'] = f'æ•°æ®åº“å‡çº§æˆåŠŸ: {current_version} -> {target_version}'
        else:
            result = migration.downgrade(current_version, target_version)
            result['message'] = f'æ•°æ®åº“é™çº§æˆåŠŸ: {current_version} -> {target_version}'
        
        result['success'] = True
        return result
        
    except Exception as e:
        logger.error(f"è¿è¡Œæ•°æ®åº“è¿ç§»å¤±è´¥: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'message': 'æ•°æ®åº“è¿ç§»å¤±è´¥'
        }


def verify_database_integrity(db_path: str) -> Dict[str, Any]:
    """
    éªŒè¯æ•°æ®åº“å®Œæ•´æ€§
    
    Args:
        db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        
    Returns:
        å®Œæ•´æ€§æ£€æŸ¥ç»“æœ
    """
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æ‰§è¡Œå®Œæ•´æ€§æ£€æŸ¥
        cursor.execute("PRAGMA integrity_check")
        integrity_result = cursor.fetchall()
        
        # æ£€æŸ¥è¿ç§»ç‰ˆæœ¬
        migration = DBMigration(db_path)
        current_version = migration.get_current_version()
        latest_version = migration.get_latest_version()
        
        # æ£€æŸ¥å¿…è¦çš„è¡¨æ˜¯å¦å­˜åœ¨
        required_tables = ['users', 'accounts', 'categories', 'transactions', 'budgets']
        existing_tables = []
        
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        for row in cursor.fetchall():
            existing_tables.append(row[0])
        
        missing_tables = [table for table in required_tables if table not in existing_tables]
        
        conn.close()
        
        return {
            'success': len(integrity_result) > 0 and integrity_result[0][0] == 'ok' and not missing_tables,
            'integrity_check': 'ok' if len(integrity_result) > 0 and integrity_result[0][0] == 'ok' else 'failed',
            'current_version': current_version,
            'latest_version': latest_version,
            'is_up_to_date': current_version == latest_version,
            'missing_tables': missing_tables,
            'message': 'æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡' if len(integrity_result) > 0 and integrity_result[0][0] == 'ok' and not missing_tables else 'æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥'
        }
        
    except Exception as e:
        logger.error(f"æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'message': 'æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥'
        }


# å½“ç›´æ¥è¿è¡Œæ­¤è„šæœ¬æ—¶
if __name__ == "__main__":
    import sys
    
    # é»˜è®¤æ•°æ®åº“è·¯å¾„
    default_db_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
                                 'data', 'finance_system.db')
    
    # å¤„ç†å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'init':
            # åˆå§‹åŒ–æ•°æ®åº“
            print(f"åˆå§‹åŒ–æ•°æ®åº“: {default_db_path}")
            init_database(default_db_path)
            print("æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸï¼")
            
        elif command == 'version':
            # æ˜¾ç¤ºå½“å‰ç‰ˆæœ¬
            migration = DBMigration(default_db_path)
            version = migration.get_current_version()
            latest = migration.get_latest_version()
            print(f"å½“å‰æ•°æ®åº“ç‰ˆæœ¬: {version}")
            print(f"æœ€æ–°å¯ç”¨ç‰ˆæœ¬: {latest}")
            print(f"æ•°æ®åº“æ˜¯å¦æ˜¯æœ€æ–°ç‰ˆæœ¬: {'æ˜¯' if version == latest else 'å¦'}")
            
        elif command == 'upgrade':
            # å‡çº§æ•°æ®åº“
            target_version = int(sys.argv[2]) if len(sys.argv) > 2 else None
            print(f"å‡çº§æ•°æ®åº“åˆ°ç‰ˆæœ¬: {target_version or 'æœ€æ–°'}")
            result = run_migration(default_db_path, target_version)
            print(f"å‡çº§ç»“æœ: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
            print(f"æ¶ˆæ¯: {result.get('message', 'æœªçŸ¥')}")
            
        elif command == 'downgrade':
            # é™çº§æ•°æ®åº“
            if len(sys.argv) > 2:
                target_version = int(sys.argv[2])
                print(f"é™çº§æ•°æ®åº“åˆ°ç‰ˆæœ¬: {target_version}")
                result = run_migration(default_db_path, target_version)
                print(f"é™çº§ç»“æœ: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
                print(f"æ¶ˆæ¯: {result.get('message', 'æœªçŸ¥')}")
            else:
                print("è¯·æŒ‡å®šç›®æ ‡ç‰ˆæœ¬: python db_migration.py downgrade <version>")
                
        elif command == 'history':
            # æ˜¾ç¤ºè¿ç§»å†å²
            migration = DBMigration(default_db_path)
            history = migration.get_migration_history_db()
            if history:
                print("è¿ç§»å†å²:")
                print("-" * 80)
                print(f"{'ç‰ˆæœ¬':<10}{'æè¿°':<40}{'åº”ç”¨æ—¶é—´':<25}")
                print("-" * 80)
                for entry in history:
                    print(f"{entry['version']:<10}{entry['description']:<40}{entry['applied_at']:<25}")
            else:
                print("æš‚æ— è¿ç§»å†å²è®°å½•")
                
        elif command == 'migrate':
            # æ‰§è¡Œæ‰€æœ‰è¿ç§»
            print(f"æ‰§è¡Œæ•°æ®åº“è¿ç§»: {default_db_path}")
            run_migrations(default_db_path)
            print("æ•°æ®åº“è¿ç§»å®Œæˆï¼")
            
        elif command == 'check':
            # æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
            result = verify_database_integrity(default_db_path)
            print("æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥:")
            print(f"æ£€æŸ¥ç»“æœ: {'é€šè¿‡' if result['success'] else 'å¤±è´¥'}")
            print(f"å®Œæ•´æ€§çŠ¶æ€: {result['integrity_check']}")
            print(f"å½“å‰ç‰ˆæœ¬: {result['current_version']}")
            print(f"æœ€æ–°ç‰ˆæœ¬: {result['latest_version']}")
            if result['missing_tables']:
                print(f"ç¼ºå¤±çš„è¡¨: {', '.join(result['missing_tables'])}")
                
        else:
            print("æœªçŸ¥å‘½ä»¤ã€‚å¯ç”¨å‘½ä»¤:")
            print("  init      - åˆå§‹åŒ–æ•°æ®åº“")
            print("  version   - æ˜¾ç¤ºå½“å‰ç‰ˆæœ¬")
            print("  upgrade   - å‡çº§æ•°æ®åº“ [ç‰ˆæœ¬å·]")
            print("  downgrade - é™çº§æ•°æ®åº“ <ç‰ˆæœ¬å·>")
            print("  history   - æ˜¾ç¤ºè¿ç§»å†å²")
            print("  migrate   - æ‰§è¡Œæ‰€æœ‰è¿ç§»")
            print("  check     - æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§")
            
    else:
        print("è¯·æŒ‡å®šå‘½ä»¤ã€‚ä½¿ç”¨æ–¹æ³•:")
        print("python db_migration.py <command>")
        print("å¯ç”¨å‘½ä»¤: init, version, upgrade, downgrade, history, migrate, check")